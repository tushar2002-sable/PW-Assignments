{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d21f1a1",
   "metadata": {},
   "source": [
    "### Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you might choose one over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db99c8",
   "metadata": {},
   "source": [
    "Ordinal encoding and label encoding are both techniques used to transform categorical variables into numerical variables. However, there are some key differences between the two techniques.\n",
    "\n",
    "**Ordinal encoding** assigns a unique integer value to each category in a categorical variable, but the `integer values have an order that reflects the order of the categories`. For example, if a categorical variable has the categories \"low\", \"medium\", and \"high\", then ordinal encoding might assign the integer values 0, 1, and 2 to the categories, respectively. This means that the integer values have a meaning, and can be interpreted as such.\n",
    "\n",
    "**Label encoding** assigns a unique integer value to each category in a categorical variable, but the `integer values do not have any order or meaning`. For example, if a categorical variable has the categories \"low\", \"medium\", and \"high\", then label encoding might assign the integer values 0, 1, and 2 to the categories, respectively. This means that the integer values are just arbitrary labels, and do not have any meaning.\n",
    "\n",
    "In general, ordinal encoding is a better choice than label encoding when the categories in a categorical variable have an order. For example, if a categorical variable represents the severity of a disease, then ordinal encoding would be a better choice than label encoding. This is because the severity of a disease has an order, and ordinal encoding would preserve this order.\n",
    "\n",
    "Label encoding is a better choice than ordinal encoding when the categories in a categorical variable do not have an order. For example, if a categorical variable represents the color of a car, then label encoding would be a better choice than ordinal encoding. This is because the color of a car does not have an order, and ordinal encoding would introduce an order that does not exist.\n",
    "\n",
    "**Example**:\n",
    "\n",
    "* **Ordinal encoding:** You are working on a project to predict the risk of heart disease. One of the features in your dataset is the \"blood pressure\" variable. This variable has the categories \"low\", \"normal\", and \"high\". You would use ordinal encoding to transform this variable into a numerical variable, because the categories in the \"blood pressure\" variable have an order.\n",
    "* **Label encoding:** You are working on a project to predict the customer satisfaction of a product. One of the features in your dataset is the \"color\" variable. This variable has the categories \"blue\", \"red\", and \"green\". You would use label encoding to transform this variable into a numerical variable, because the categories in the \"color\" variable do not have an order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2c9ba",
   "metadata": {},
   "source": [
    "### Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df5397",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding (TGOE) is a feature encoding technique used in machine learning to convert categorical variables into numerical representations based on the relationship between the categorical variable and the target variable. It is particularly useful when dealing with ordinal categorical variables, where the categories have a meaningful order or hierarchy.\n",
    "\n",
    "The basic idea behind Target Guided Ordinal Encoding is to assign a numerical value to each category of the ordinal variable, such that the assigned values reflect the ordinal relationship between the categories while also capturing the information about the target variable's distribution within each category. This helps the machine learning model to better understand the patterns and relationships between the features and the target.\n",
    "\n",
    "Here's a step-by-step explanation of how Target Guided Ordinal Encoding works:\n",
    "\n",
    "1. **Calculate Target Mean or Probability**: For each category of the ordinal variable, calculate the mean (or probability) of the target variable within that category. This means you're finding the average target value or the probability of a certain target outcome for each category.\n",
    "\n",
    "2. **Sort Categories by Target Mean/Probability**: Sort the categories in ascending order based on their calculated target mean or probability. This sorting reflects the ordinal relationship between the categories.\n",
    "\n",
    "3. **Assign Ordinal Ranks**: Assign ordinal ranks (integer values) to the sorted categories. The category with the lowest target mean/probability gets the lowest rank (e.g., 1), the next category gets the next rank (e.g., 2), and so on.\n",
    "\n",
    "4. **Map Categories to Ranks**: Replace the original categorical values of the ordinal variable with their corresponding assigned ranks.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let's say you're working on a dataset of customer reviews for a product, and one of the features is \"Review Rating,\" which represents the rating given by customers ranging from \"Poor\" to \"Excellent.\" The categories have a clear order (\"Poor\" < \"Fair\" < \"Good\" < \"Very Good\" < \"Excellent\").\n",
    "\n",
    "Original data:\n",
    "- Poor\n",
    "- Fair\n",
    "- Good\n",
    "- Very Good\n",
    "- Excellent\n",
    "- Fair\n",
    "- Good\n",
    "\n",
    "You have a binary target variable indicating whether the customer made a repeat purchase (1) or not (0).\n",
    "\n",
    "1. Calculate Target Mean:\n",
    "   - Poor: 0.2\n",
    "   - Fair: 0.4\n",
    "   - Good: 0.6\n",
    "   - Very Good: 0.8\n",
    "   - Excellent: 1.0\n",
    "\n",
    "2. Sort Categories by Target Mean:\n",
    "   - Poor\n",
    "   - Fair\n",
    "   - Good\n",
    "   - Very Good\n",
    "   - Excellent\n",
    "\n",
    "3. Assign Ordinal Ranks:\n",
    "   - Poor: 1\n",
    "   - Fair: 2\n",
    "   - Good: 3\n",
    "   - Very Good: 4\n",
    "   - Excellent: 5\n",
    "\n",
    "4. Map Categories to Ranks:\n",
    "   - 1\n",
    "   - 2\n",
    "   - 3\n",
    "   - 4\n",
    "   - 5\n",
    "   - 2\n",
    "   - 3\n",
    "\n",
    "In this example, the \"Review Rating\" feature has been transformed using Target Guided Ordinal Encoding, and the original ordinal relationship has been preserved while incorporating information about the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a637565",
   "metadata": {},
   "source": [
    "### Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b328d9f",
   "metadata": {},
   "source": [
    "In statistics, covariance is a measure of how two variables are related to each other. It is calculated as the average of the product of the deviations from the mean for each variable. The covariance of two variables can be positive, negative, or zero.\n",
    "\n",
    "A positive covariance indicates that the two variables are positively correlated, meaning that they tend to move in the same direction. For example, if the covariance between two variables is positive, then as one variable increases, the other variable is also likely to increase.\n",
    "\n",
    "A negative covariance indicates that the two variables are negatively correlated, meaning that they tend to move in opposite directions. For example, if the covariance between two variables is negative, then as one variable increases, the other variable is likely to decrease.\n",
    "\n",
    "A covariance of zero indicates that there is no relationship between the two variables.\n",
    "\n",
    "Covariance is an important measure in statistical analysis because it can help to identify relationships between variables. It can also be used to calculate other statistical measures, such as the correlation coefficient and the variance.\n",
    "\n",
    "The covariance of two variables is calculated as follows:\n",
    "\n",
    "```\n",
    "cov(x, y) = E[(x - mean(x))(y - mean(y))]\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "* `cov(x, y)` is the covariance of the two variables x and y.\n",
    "* `E` is the expected value.\n",
    "* `x` is the value of variable x.\n",
    "* `mean(x)` is the mean of variable x.\n",
    "* `y` is the value of variable y.\n",
    "* `mean(y)` is the mean of variable y.\n",
    "\n",
    "The covariance of two variables can be interpreted as the average of the product of the deviations from the mean for each variable. This means that the covariance is a measure of how much the two variables vary together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2486a437",
   "metadata": {},
   "source": [
    "### Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5003c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     2         2\n",
      "1      1     1         0\n",
      "2      0     0         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a pandas dataframe\n",
    "data = {'Color': ['red', 'green', 'blue'],\n",
    "        'Size': ['small', 'medium', 'large'],\n",
    "        'Material': ['wood', 'metal', 'plastic']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create instances of label encoders for each column\n",
    "color_encoder = LabelEncoder()\n",
    "size_encoder = LabelEncoder()\n",
    "material_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each column\n",
    "df['Color'] = color_encoder.fit_transform(df['Color'])\n",
    "df['Size'] = size_encoder.fit_transform(df['Size'])\n",
    "df['Material'] = material_encoder.fit_transform(df['Material'])\n",
    "\n",
    "# Print the encoded data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc103c40",
   "metadata": {},
   "source": [
    "### Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2457a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      " [[1.57e+02 2.30e+05 2.80e+01]\n",
      " [2.30e+05 6.95e+08 3.00e+04]\n",
      " [2.80e+01 3.00e+04 1.00e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data for Age, Income, and Education level\n",
    "age = [28, 35, 42, 50, 60]\n",
    "income = [50000, 75000, 100000, 120000, 90000]\n",
    "education_level = [12, 16, 18, 14, 20]\n",
    "\n",
    "# Stack the variables into a matrix\n",
    "data = np.vstack((age, income, education_level))\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(data)\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(\"Covariance Matrix:\\n\", cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c8985",
   "metadata": {},
   "source": [
    "Certainly, let's interpret the results of the covariance matrix for the given variables:\n",
    "\n",
    "```plaintext\n",
    "[[1.57e+02 2.30e+05 2.80e+01]\n",
    " [2.30e+05 6.95e+08 3.00e+04]\n",
    " [2.80e+01 3.00e+04 1.00e+01]]\n",
    "```\n",
    "\n",
    "1. **Age Variance (1,1 Element)**: The variance of 'Age' is approximately 157. This indicates that the ages in the dataset have relatively low variability around the mean age. In other words, the ages of the individuals are not spread out too much from the average age.\n",
    "\n",
    "2. **Income Variance (2,2 Element)**: The variance of 'Income' is approximately 6.95e+08 (695,000,000). This high variance suggests that there is significant variability in income among the individuals in the dataset. Some individuals may have much higher or lower incomes compared to the mean income.\n",
    "\n",
    "3. **Education Variance (3,3 Element)**: The variance of 'Education level' is approximately 10. This relatively low variance suggests that the education levels of the individuals in the dataset are not very spread out from the mean education level.\n",
    "\n",
    "4. **Age-Income Covariance (1,2 and 2,1 Elements)**: The covariance between 'Age' and 'Income' is approximately 2.30e+05 (230,000). This positive covariance indicates that, on average, as age increases, income tends to increase as well. The magnitude of the covariance suggests a moderate relationship.\n",
    "\n",
    "5. **Age-Education Covariance (1,3 and 3,1 Elements)**: The covariance between 'Age' and 'Education level' is approximately 28. This positive covariance suggests a weak positive relationship between age and education level. However, the magnitude of the covariance indicates that this relationship is very weak.\n",
    "\n",
    "6. **Income-Education Covariance (2,3 and 3,2 Elements)**: The covariance between 'Income' and 'Education level' is approximately 3.00e+04 (30,000). This positive covariance indicates that, on average, as income increases, education level tends to increase as well. The magnitude of the covariance suggests a relatively strong relationship.\n",
    "\n",
    "In summary, the covariance matrix provides insights into the relationships and variabilities between the variables. It indicates that there is a moderate positive relationship between age and income, and relatively weak relationships between age and education level, as well as between income and education level. The variances indicate how spread out the values are around the mean for each variable. Keep in mind that covariance does not indicate causation, only association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264373f6",
   "metadata": {},
   "source": [
    "### Q6. You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for each variable, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91355bd7",
   "metadata": {},
   "source": [
    "The encoding methods that I would use for the categorical variables \"Gender\", \"Education Level\", and \"Employment Status\" are:\n",
    "\n",
    "* **Gender:** One-hot encoding. This is because Gender is a nominal variable with two categories, so one-hot encoding will create two new binary variables, one for Male and one for Female. This will allow the machine learning model to learn the importance of each gender category.\n",
    "* **Education Level:** Label encoding. This is because Education Level is an ordinal variable with four categories, so label encoding will assign each category a unique integer value. This will allow the machine learning model to learn the order of the education levels.\n",
    "* **Employment Status:** One-hot encoding. This is because Employment Status is a nominal variable with three categories, so one-hot encoding will create three new binary variables, one for Unemployed, one for Part-Time, and one for Full-Time. This will allow the machine learning model to learn the importance of each employment status category.\n",
    "\n",
    "Here is a table summarizing the encoding methods that I would use for each categorical variable:\n",
    "\n",
    "| Variable | Encoding Method | Reason |\n",
    "|---|---|---|\n",
    "| Gender | One-hot encoding | Nominal variable with two categories |\n",
    "| Education Level | Label encoding | Ordinal variable with four categories |\n",
    "| Employment Status | One-hot encoding | Nominal variable with three categories |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212132a0",
   "metadata": {},
   "source": [
    "### Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/ East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df4efdd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "749b901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between variables:\n",
      "     Variable 1   Variable 2  Covariance\n",
      "0             0            1       -0.10\n",
      "1             0            2       -0.20\n",
      "2             0            3       -0.10\n",
      "3             0            4        0.15\n",
      "4             0  Temperature        1.25\n",
      "5             0     Humidity       -1.25\n",
      "6             1            2        0.15\n",
      "7             1            3       -0.05\n",
      "8             1            4       -0.05\n",
      "9             1  Temperature       -2.50\n",
      "10            1     Humidity        2.50\n",
      "11            2            3       -0.10\n",
      "12            2            4       -0.10\n",
      "13            2  Temperature       -3.75\n",
      "14            2     Humidity        3.75\n",
      "15            3            4       -0.05\n",
      "16            3  Temperature        2.50\n",
      "17            3     Humidity       -2.50\n",
      "18            4  Temperature        1.25\n",
      "19            4     Humidity       -1.25\n",
      "20  Temperature     Humidity      -62.50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Create a dataset\n",
    "data = {\n",
    "    \"Temperature\": [75, 80, 85, 90, 95],\n",
    "    \"Humidity\": [60, 55, 50, 45, 40],\n",
    "    \"Weather Condition\": [\"Sunny\", \"Cloudy\", \"Rainy\", \"Rainy\", \"Cloudy\"],\n",
    "    \"Wind Direction\": [\"North\", \"North\", \"East\", \"West\", \"South\"]\n",
    "}\n",
    "\n",
    "# Convert data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_categorical = encoder.fit_transform(df[[\"Weather Condition\", \"Wind Direction\"]])\n",
    "\n",
    "# Convert the encoded categorical array into a DataFrame\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "all_vars = pd.concat([encoded_categorical_df, df[[\"Temperature\", \"Humidity\"]]], axis=1)\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(all_vars, rowvar=False)\n",
    "\n",
    "# Extract variable names\n",
    "variable_names = encoded_categorical_df.columns.tolist() + [\"Temperature\", \"Humidity\"]\n",
    "\n",
    "# Create a list to store covariances\n",
    "covariances = []\n",
    "\n",
    "# Fill the list with covariances\n",
    "for i in range(len(variable_names)):\n",
    "    for j in range(i + 1, len(variable_names)):\n",
    "        covariance = cov_matrix[i, j]\n",
    "        covariances.append((variable_names[i], variable_names[j], covariance))\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "covariance_df = pd.DataFrame(covariances, columns=[\"Variable 1\", \"Variable 2\", \"Covariance\"])\n",
    "\n",
    "# Print the covariance table\n",
    "print(\"Covariance between variables:\")\n",
    "print(covariance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb71fd",
   "metadata": {},
   "source": [
    "Here's an interpretation of some of the values in the provided covariance matrix:\n",
    "\n",
    "**1. Covariance between Weather Condition and Wind Direction:** The covariance values between these categorical variables suggest weak relationships between them. The negative covariances (e.g., -0.10 and -0.20) indicate that when one category is present in Weather Condition, it is less likely to be present in Wind Direction.\n",
    "\n",
    "**2. Covariance between Weather Condition and Temperature/Humidity:** The positive and negative covariances between categorical variables and continuous variables suggest that there might be some relationships, but the magnitudes of the covariances are relatively small. For example, the covariance between Weather Condition and Temperature is 0.15, indicating a weak tendency for certain weather conditions to occur with higher temperatures.\n",
    "\n",
    "**3. Covariance between Temperature and Humidity:** The covariance values between these continuous variables provide insights into their relationship. A positive covariance of 1.25 suggests that higher temperatures tend to be associated with higher humidity levels. Conversely, a negative covariance of -1.25 indicates that lower temperatures tend to be associated with lower humidity levels.\n",
    "\n",
    "**4. Covariance between Temperature and Humidity (Flipped):** The negative value of -62.50 for Temperature and Humidity is an indicator of strong negative correlation. This suggests that as temperature increases, humidity tends to decrease, and vice versa. The magnitude of this negative covariance suggests a significant inverse relationship between these two variables.\n",
    "\n",
    "Overall, interpreting covariance values involves considering both the magnitude and sign of the covariances. However, it's important to note that covariance does not provide a standardized measure of the strength of the relationship between variables, as it depends on the scales of the variables. For a more standardized measure, you might consider calculating the correlation coefficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
