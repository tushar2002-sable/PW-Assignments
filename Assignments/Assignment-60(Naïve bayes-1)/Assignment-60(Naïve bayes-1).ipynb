{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "600e7f30",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a16a4",
   "metadata": {},
   "source": [
    "Bayes' theorem is a theorem in probability theory that describes the probability of an event, given the occurrence of another event. It is named after Thomas Bayes, an English mathematician who published the theorem in 1763.\n",
    "\n",
    "Bayes' theorem can be used to update our beliefs about the probability of an event, given new information. For example, let's say we are trying to determine the probability that a patient has cancer, given that they have a positive test result. The prior probability of the patient having cancer is the probability that they would have a positive test result, even if they did not have cancer. The likelihood of the test result is the probability that a patient with cancer would have a positive test result. The posterior probability of the patient having cancer is the probability that they have cancer, given that they have a positive test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf7de5",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0514732",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "```\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "* $P(A|B)$ is the **posterior probability** of event A occurring, given that event B has already occurred\n",
    "* $P(B|A)$ is the **likelihood** of event B occurring, given that event A has already occurred\n",
    "* $P(A)$ is the **prior probability** of event A occurring\n",
    "* $P(B)$ is the **prior probability** of event B occurring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7150640e",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a4eff",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in a variety of practical applications, including:\n",
    "\n",
    "* **Medical diagnosis:** Bayes' theorem can be used to update the probability of a patient having a disease, given the results of a medical test. For example, a patient may have a positive test result for cancer. Bayes' theorem can be used to calculate the probability that the patient actually has cancer, given the positive test result.\n",
    "* **Credit risk assessment:** Bayes' theorem can be used to update the probability that a borrower will default on a loan, given their credit history. For example, a borrower may have a history of late payments. Bayes' theorem can be used to calculate the probability that the borrower will default on a new loan, given their credit history.\n",
    "* **Fraud detection:** Bayes' theorem can be used to update the probability that a transaction is fraudulent, given the characteristics of the transaction. For example, a transaction may be made from an unusual location. Bayes' theorem can be used to calculate the probability that the transaction is fraudulent, given the unusual location.\n",
    "* **Spam filtering:** Bayes' theorem can be used to update the probability that an email is spam, given the content of the email. For example, an email may contain certain keywords that are commonly used in spam emails. Bayes' theorem can be used to calculate the probability that the email is spam, given the presence of these keywords.\n",
    "* **Natural language processing:** Bayes' theorem can be used to update the probability that a word belongs to a certain category, given the context of the word. For example, the word \"bank\" can be used to refer to a financial institution or to the side of a river. Bayes' theorem can be used to calculate the probability that the word \"bank\" refers to a financial institution, given the context in which it is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb7b301",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3effb20",
   "metadata": {},
   "source": [
    "Bayes' theorem is a theorem in probability theory that describes the probability of an event, given the occurrence of another event. Conditional probability is the probability of an event occurring, given that another event has already occurred.\n",
    "\n",
    "The relationship between Bayes' theorem and conditional probability is that Bayes' theorem can be used to calculate the conditional probability of event A occurring, given that event B has already occurred.\n",
    "\n",
    "For example, let's say we are trying to determine the probability that a patient has cancer, given that they have a positive test result. The prior probability of the patient having cancer is the probability that they would have a positive test result, even if they did not have cancer. The likelihood of the test result is the probability that a patient with cancer would have a positive test result. The posterior probability of the patient having cancer is the probability that they have cancer, given that they have a positive test result.\n",
    "\n",
    "The likelihood of the test result is typically provided by the medical laboratory that performs the test. The prior probability of the patient having cancer can be estimated from medical records or from population studies.\n",
    "\n",
    "The posterior probability is the conditional probability of the patient having cancer, given that they have a positive test result. It is calculated by multiplying the likelihood of the test result, given that the patient has cancer, by the prior probability of the patient having cancer, and then dividing by the prior probability of the test result.\n",
    "\n",
    "In other words, Bayes' theorem is a way of calculating the conditional probability of event A occurring, given that event B has already occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cb29f",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af95dc",
   "metadata": {},
   "source": [
    "There are three main types of Naive Bayes classifiers:\n",
    "\n",
    "* **Gaussian Naive Bayes:** This classifier assumes that the features are normally distributed. It is a good choice for problems where the features are continuous and have a Gaussian distribution.\n",
    "* **Multinomial Naive Bayes:** This classifier assumes that the features are discrete and can take on a limited number of values. It is a good choice for problems where the features are categorical, such as text classification.\n",
    "* **Bernoulli Naive Bayes:** This classifier assumes that the features are binary, such as whether a word is present in a document or not. It is a good choice for problems where the features are binary, such as spam filtering.\n",
    "\n",
    "The best type of Naive Bayes classifier to use for a given problem will depend on the nature of the data and the goals of the analysis.\n",
    "\n",
    "Here are some factors to consider when choosing a Naive Bayes classifier:\n",
    "\n",
    "* **The type of data:** If the data is continuous, then Gaussian Naive Bayes is a good choice. If the data is discrete, then Multinomial Naive Bayes is a good choice. If the data is binary, then Bernoulli Naive Bayes is a good choice.\n",
    "* **The number of features:** If the number of features is large, then Multinomial Naive Bayes may not be a good choice, as it can be computationally expensive to train. In this case, Gaussian Naive Bayes or Bernoulli Naive Bayes may be a better choice.\n",
    "* **The goals of the analysis:** If the goal is to make accurate predictions, then Gaussian Naive Bayes or Multinomial Naive Bayes may be a good choice. If the goal is to understand the relationship between the features and the target variable, then Bernoulli Naive Bayes may be a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da00da",
   "metadata": {},
   "source": [
    "### Q6. Assignment:\n",
    "### You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "- Class    X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "```\n",
    "  A    3    3    4    4    3    3    3\n",
    "  B    2    2    1    2    2    2    3\n",
    "```\n",
    "### Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bfdac",
   "metadata": {},
   "source": [
    "To classify a new instance using Naive Bayes, we can calculate the probability of the instance belonging to each class (Class A and Class B) and then choose the class with the highest probability.\n",
    "\n",
    "In Naive Bayes, we compute the posterior probability of each class given the observed features (X1 = 3 and X2 = 4) using Bayes' theorem. Assuming equal prior probabilities for each class (P(Class A) = P(Class B)), you can compare the likelihood of the observed features for each class and choose the class with the higher likelihood.\n",
    "\n",
    "Let's calculate the likelihood for each class:\n",
    "\n",
    "For Class A:\n",
    "- P(X1 = 3 | Class A) = 4/13 (frequency of X1=3 for Class A)\n",
    "- P(X2 = 4 | Class A) = 3/13 (frequency of X2=4 for Class A)\n",
    "\n",
    "Likelihood of Class A = P(X1 = 3 | Class A) * P(X2 = 4 | Class A) = (4/13) * (3/13)\n",
    "\n",
    "For Class B:\n",
    "- P(X1 = 3 | Class B) = 1/7 (frequency of X1=3 for Class B)\n",
    "- P(X2 = 4 | Class B) = 3/7 (frequency of X2=4 for Class B)\n",
    "\n",
    "Likelihood of Class B = P(X1 = 3 | Class B) * P(X2 = 4 | Class B) = (1/7) * (3/7)\n",
    "\n",
    "Now, calculate the unnormalized posterior probabilities for each class:\n",
    "\n",
    "Posterior Probability for Class A = Prior Probability * Likelihood of Class A\n",
    "Posterior Probability for Class B = Prior Probability * Likelihood of Class B\n",
    "\n",
    "Since the prior probabilities are equal (P(Class A) = P(Class B)), we can compare the unnormalized posterior probabilities directly:\n",
    "\n",
    "Posterior Probability for Class A = (1/2) * [(4/13) * (3/13)]\n",
    "Posterior Probability for Class B = (1/2) * [(1/7) * (3/7)]\n",
    "\n",
    "Now, calculate these probabilities:\n",
    "\n",
    "Posterior Probability for Class A ≈ 0.034376\n",
    "Posterior Probability for Class B ≈ 0.022959\n",
    "\n",
    "Since the posterior probability for Class A is higher than that for Class B, Naive Bayes would predict that the new instance with features X1 = 3 and X2 = 4 belongs to Class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
