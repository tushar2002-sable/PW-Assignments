{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4af1e960",
   "metadata": {},
   "source": [
    "##### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edaf5e",
   "metadata": {},
   "source": [
    "Here are the assumptions required to use ANOVA:\n",
    "\n",
    "* **Normality:** The data must be normally distributed. This means that the data should be bell-shaped and symmetrical. If the data is not normally distributed, then the results of the ANOVA test may be inaccurate.\n",
    "* **Homogeneity of variance:** The variances of the different groups must be equal. This means that the data points within each group should vary around the mean by about the same amount. If the variances are not equal, then the results of the ANOVA test may be biased.\n",
    "* **Absence of Outliers** Outliers can also impact the validity of the results of an ANOVA test. Outliers are data points that are significantly different from the rest of the data. If there are outliers in the data, then they can skew the results of the ANOVA test. Outliers need to be removed from the dataset.\n",
    "* **Independence:** The data points must be independent of each other. This means that the value of one data point should not affect the value of another data point. If the data points are not independent, then the results of the ANOVA test may be inaccurate.\n",
    "\n",
    "Here are some examples of violations that could impact the validity of the results of an ANOVA test:\n",
    "\n",
    "* **Non-normality:** If the data is not normally distributed, then the results of the ANOVA test may be inaccurate. For example, if the data is skewed or has outliers, then the results of the ANOVA test may not be valid.\n",
    "* **Heterogeneity of variance:** If the variances of the different groups are not equal, then the results of the ANOVA test may be biased. For example, if one group has a much larger variance than the other groups, then the results of the ANOVA test may not be valid.\n",
    "* **Outliers:** Outliers can skew the distribution of the residuals from the ANOVA test. This can lead to inaccurate p-values and confidence intervals.\n",
    "* **Dependence:** If the data points are not independent of each other, then the results of the ANOVA test may be inaccurate. For example, if the data points are collected from the same people, then the results of the ANOVA test may not be valid.\n",
    "\n",
    "It is important to note that the assumptions of ANOVA are not always met in practice. However, if the assumptions are not met, then the results of the ANOVA test may be inaccurate. Therefore, it is important to carefully check the data for violations of the assumptions before conducting an ANOVA test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dca000",
   "metadata": {},
   "source": [
    "##### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608d59c",
   "metadata": {},
   "source": [
    "The main three types of ANNOVA are represented below:\n",
    "\n",
    "* **One-way ANOVA** has one independent variable with at least two levels, and the levels are independent of each other. For example, you could use one-way ANOVA to compare the mean test scores of students who took different types of math classes.\n",
    "* **Repeated measures ANOVA** also has one independent variable with at least two levels, but the levels are dependent on each other. This means that the same participants are measured in each level. For example, you could use repeated measures ANOVA to compare the mean test scores of students who took the same math test twice.\n",
    "* **Fractional ANOVA** has two or more independent variables, each with at least two levels. The levels can be either independent or dependent of each other. For example, you could use fractional ANOVA to compare the mean test scores of students who took different types of math classes, while also taking into account the effects of their gender and their grade level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55222ea0",
   "metadata": {},
   "source": [
    "##### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e40a32",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the process of decomposing the total variability in the data into different Sure. In the context of ANOVA, the terms *within*, *between*, and *total* refer to different components of the total variance in a dataset.\n",
    "\n",
    "* **Within-group variance** (also known as **error variance**) refers to the variation within each group of data. This variation is due to factors that are not related to the independent variable, such as individual differences and random error.\n",
    "* **Between-group variance** refers to the variation between the different groups of data. This variation is due to the independent variable, and it is the amount of variance that we are trying to explain with ANOVA.\n",
    "* **Total variance** refers to the total variation in the dataset. It is the sum of the within-group variance and the between-group variance.\n",
    "\n",
    "The partitioning of variance is the process of dividing the total variance into these three components. This can be done using a statistical technique called **analysis of variance** (ANOVA).\n",
    "\n",
    "The partitioning of variance is important in ANOVA because it helps us answer the following questions:\n",
    "\n",
    "1. Is there a significant difference between the group means?\n",
    "2. How much of the total variability in the dependent variable can be attributed to the differences between the groups?\n",
    "3. How much of the total variability in the dependent variable is due to random variability or measurement error within each group?\n",
    "\n",
    "By understanding the partitioning of variance, researchers can identify the factors that contribute significantly to the variation in the dependent variable and gain insights into the relationships between the independent and dependent variables. It also guides the interpretation of ANOVA results and provides a basis for making informed decisions about the significance of different sources of variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509907f7",
   "metadata": {},
   "source": [
    "##### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e424590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE:  22.0\n",
      "SST:  22.0\n",
      "SSR:  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Dataset\n",
    "data = {\n",
    "    \"group\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"],\n",
    "    \"values\": [10, 12, 14, 8, 10, 12],\n",
    "        }\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate Over all mean of data set\n",
    "overall_mean = np.mean(df['values'])\n",
    "\n",
    "# Calculate mean of each groups i.e., A, B and C\n",
    "group_means = df.groupby(\"group\")['values'].mean()\n",
    "\n",
    "# Calculate efficeint sum of squares\n",
    "squared_mean = []\n",
    "for group, mean in group_means.items():\n",
    "    group_data = df[df[\"group\"] == group]['values']\n",
    "    squared_mean.append(np.sum((group_data - mean)**2))\n",
    "\n",
    "SSE = np.sum(squared_mean)\n",
    "SST = np.sum((df['values'] - overall_mean)**2)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"SSE: \", SSE)\n",
    "print(\"SST: \", SST)\n",
    "print(\"SSR: \", SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d01a3",
   "metadata": {},
   "source": [
    "##### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019b4a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statsmodels ANOVA:\n",
      "                      df        sum_sq       mean_sq    F  PR(>F)\n",
      "C(group1)            2.0  1.577722e-29  7.888609e-30  0.0     NaN\n",
      "C(group2)            1.0  6.666667e-01  6.666667e-01  0.0     NaN\n",
      "C(group1):C(group2)  2.0  2.133333e+01  1.066667e+01  0.0     NaN\n",
      "Residual             0.0  1.104405e-28           inf  NaN     NaN\n",
      "\n",
      "Pingouin ANOVA:\n",
      "            Source         SS  DF         MS  np2\n",
      "0           group1   0.000000   2   0.000000  NaN\n",
      "1           group2   0.666667   1   0.666667  1.0\n",
      "2  group1 * group2  21.333333   2  10.666667  1.0\n",
      "3         Residual   0.000000   0        NaN  NaN\n",
      "\n",
      "\n",
      "\n",
      "Researchpy ANOVA:\n",
      "               N  Mean  SD  SE  95% Conf.  Interval\n",
      "group1 group2                                      \n",
      "A      1       1  10.0 NaN NaN        NaN       NaN\n",
      "       2       1  12.0 NaN NaN        NaN       NaN\n",
      "B      1       1  14.0 NaN NaN        NaN       NaN\n",
      "       2       1   8.0 NaN NaN        NaN       NaN\n",
      "C      1       1  10.0 NaN NaN        NaN       NaN\n",
      "       2       1  12.0 NaN NaN        NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\statsmodels\\stats\\anova.py:138: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  (model.ssr / model.df_resid))\n",
      "C:\\Program Files\\Python311\\Lib\\site-packages\\pingouin\\parametric.py:1091: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ms_resid = ss_resid / df_resid\n",
      "C:\\Program Files\\Python311\\Lib\\site-packages\\pingouin\\parametric.py:1112: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  np2_fac1 = ss_fac1 / (ss_fac1 + ss_resid)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "import researchpy as rp\n",
    "\n",
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"group1\": [\"A\", \"A\", \"B\", \"B\", \"C\", \"C\"],\n",
    "    \"group2\": [\"1\", \"2\", \"1\", \"2\", \"1\", \"2\"],\n",
    "    \"values\": [10, 12, 14, 8, 10, 12],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA using statsmodels\n",
    "model = sm.formula.ols('values ~ C(group1) + C(group2) + C(group1):C(group2)', data=df).fit()\n",
    "anova_table_statsmodels = sm.stats.anova_lm(model)\n",
    "print(\"Statsmodels ANOVA:\")\n",
    "print(anova_table_statsmodels)\n",
    "\n",
    "\n",
    "# Perform two-way ANOVA using pingouin\n",
    "result_pingouin = pg.anova(data=df, dv='values', between=['group1', 'group2'])\n",
    "print(\"\\nPingouin ANOVA:\")\n",
    "print(result_pingouin)\n",
    "\n",
    "# Perform two-way ANOVA using researchpy\n",
    "result_researchpy = rp.summary_cont(df['values'].groupby([df['group1'], df['group2']]))\n",
    "print(\"\\nResearchpy ANOVA:\")\n",
    "print(result_researchpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780ebd3",
   "metadata": {},
   "source": [
    "Let's interpret the results of the two-way ANOVA from each library:\n",
    "\n",
    "1. Statsmodels ANOVA:\n",
    "   - The ANOVA table from `statsmodels` shows the main effects and interaction effect for both group1 and group2.\n",
    "   - The F-statistic (F) is used to test the null hypothesis that the means of the groups are equal. Here, all F-statistics are approximately 0, and the associated p-values (PR(>F)) are NaN, indicating that the means are not significantly different.\n",
    "   - The sum of squares (sum_sq) represents the variability in the data explained by each factor, while the mean sum of squares (mean_sq) represents the variability explained per degree of freedom.\n",
    "   - The degrees of freedom (df) correspond to the number of groups minus 1 for each factor and the interaction term, and the Residual df is 0.\n",
    "   - The results indicate that there is no significant main effect or interaction effect, as all p-values are NaN.\n",
    "\n",
    "2. Pingouin ANOVA:\n",
    "   - The ANOVA table from `pingouin` provides a summary of the sources of variation in the data.\n",
    "   - The Source column lists the main effects (group1 and group2) and the interaction effect (group1 * group2).\n",
    "   - The SS column represents the sum of squares for each effect, which measures the total variability in the data explained by each factor.\n",
    "   - The DF column corresponds to the degrees of freedom for each factor, which is the number of groups minus 1 for main effects and the product of the number of levels in both factors minus 1 for the interaction effect.\n",
    "   - The MS column represents the mean sum of squares for each factor, which measures the variability explained per degree of freedom.\n",
    "   - The np2 column represents the partial eta-squared, a measure of effect size. Here, it is 1.0 for both main effects and the interaction effect, indicating that each factor explains 100% of the variability in the data.\n",
    "   - The results indicate that there are significant main effects of group2 and the interaction effect, but no significant main effect of group1.\n",
    "\n",
    "3. Researchpy ANOVA:\n",
    "   - The `researchpy` ANOVA output provides a table of means, standard deviations, standard errors, and confidence intervals for each combination of groups in group1 and group2.\n",
    "   - Since `researchpy` does not provide the ANOVA table with p-values and F-statistics, we cannot directly determine the statistical significance of the main effects and interaction effect from this output.\n",
    "\n",
    "In summary, the ANOVA results indicate that there is no significant main effect of group1, but there are significant main effects of group2 and the interaction effect between group1 and group2. The `researchpy` output provides descriptive statistics but does not include p-values and F-statistics for testing the significance of the effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cd2694",
   "metadata": {},
   "source": [
    "##### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6cfc99",
   "metadata": {},
   "source": [
    "In this case, we obtained an F-statistic of 5.23 and a p-value of 0.02. The p-value represents the probability of observing the results (or more extreme results) if there were no true differences between the groups. A p-value of 0.02 indicates that there is only a 2% chance of obtaining the observed differences between the group means if there were no actual differences.\n",
    "\n",
    "Since the p-value is less than the chosen significance level (commonly 0.05), we reject the null hypothesis. The null hypothesis in this context states that there are no significant differences between the groups. Therefore, with a p-value of 0.02, we have evidence to support the alternative hypothesis, which states that there are significant differences between at least one pair of groups.\n",
    "\n",
    "To interpret these results:\n",
    "- We can conclude that there are significant differences between the group means.\n",
    "- However, the one-way ANOVA does not tell us which specific groups are different from each other; it only informs us that there are differences somewhere among the groups.\n",
    "- To identify which group(s) differ significantly, post hoc tests or pairwise comparisons are typically performed.\n",
    "\n",
    "In summary, the obtained F-statistic of 5.23 with a p-value of 0.02 indicates that there are significant differences between the groups. Further post hoc analyses can help identify which specific group(s) contribute to the observed differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3d1ec",
   "metadata": {},
   "source": [
    "##### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a468fc1",
   "metadata": {},
   "source": [
    "There are a few different ways to handle missing data in a repeated measures ANOVA. The best method to use depends on the specific research question and the data.\n",
    "\n",
    "**Listwise deletion** is the most common method for handling missing data. With listwise deletion, any participant with missing data for any of the variables is dropped from the analysis. This is a conservative method, but it can also lead to a loss of power.\n",
    "\n",
    "**Pairwise deletion** is another method for handling missing data. With pairwise deletion, only the data for the variables that are not missing for a particular participant are used in the analysis. This is a less conservative method than listwise deletion, but it can also lead to a loss of power.\n",
    "\n",
    "**Multiple Imputation:** This involves creating multiple plausible imputed datasets, each with a set of imputed values for the missing data, based on a statistical model. The analysis is then conducted on each imputed dataset, and the results are pooled to provide more accurate estimates and standard errors. This method is more statistically rigorous but requires more computation.\n",
    "\n",
    "**Mixed Effects Models:** Mixed effects models (also known as hierarchical linear models or multilevel models) can handle missing data by utilizing all available data while accounting for the hierarchical structure of the repeated measures. These models can provide unbiased estimates even with missing data if the data are missing at random.\n",
    "\n",
    "\n",
    "\n",
    "The potential consequences of using different methods to handle missing data in a repeated measures ANOVA include:\n",
    "\n",
    "* **Loss of power:** If too much data is missing, the analysis may not have enough power to detect a significant difference.\n",
    "* **Bias:** The results of the analysis may be biased if the missing data is not random.\n",
    "* **Inconsistency:** The results of the analysis may be inconsistent if different methods are used to handle missing data.\n",
    "* **Precision:** Methods like multiple imputation can provide more precise estimates and standard errors compared to simple imputation methods.\n",
    "\n",
    "The best way to handle missing data in a repeated measures ANOVA is to use a method that is appropriate for the specific research question and the data. It is also important to be aware of the potential consequences of using different methods to handle missing data.\n",
    "\n",
    "Here are some additional considerations when handling missing data in a repeated measures ANOVA:\n",
    "\n",
    "* The number of missing observations: If there are a small number of missing observations, listwise deletion may be a reasonable option. However, if there are a large number of missing observations, listwise deletion may result in a loss of power that is too great.\n",
    "* The pattern of missing data: If the missing data is random, then listwise deletion or pairwise deletion may be appropriate. However, if the missing data is not random, then imputation may be a better option.\n",
    "* The type of data: If the data is continuous, then imputation may be a good option. However, if the data is categorical, then imputation may not be possible.\n",
    "\n",
    "It is important to note that there is no one-size-fits-all approach to handling missing data. The best method to use depends on the specific research question and the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bfc5e8",
   "metadata": {},
   "source": [
    "##### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c4ccc",
   "metadata": {},
   "source": [
    "Post-hoc tests are statistical tests that are used to compare the means of two or more groups after an ANOVA has found a significant difference between the groups(like there was the significant difference between the groups in Q5). There are many different post-hoc tests available, and the choice of which test to use depends on the specific research question and the data.\n",
    "\n",
    "Some of the most commonly used post-hoc tests include:\n",
    "\n",
    "* **Tukey's HSD test:** Tukey's HSD test is a popular post hoc test because it is relatively conservative, meaning that it is less likely to find a significant difference between groups when there is actually no difference.\n",
    "* **Bonferroni correction:** The Bonferroni correction is a more conservative post hoc test than the Tukey's HSD test. This means that it is less likely to find a significant difference between groups, even when there is actually a difference.\n",
    "* **Scheffe test:** The Scheffe test is a less conservative post hoc test than the Tukey's HSD test. This means that it is more likely to find a significant difference between groups, even when there is actually no difference.\n",
    "* **Dunnett's test:** Dunnett's test is a post hoc test that is specifically designed for comparing a control group to other groups.\n",
    "\n",
    "The results of the post hoc tests can be used to identify which specific groups are different from each other. Once the specific groups that are different have been identified, the researcher can then investigate the reasons for the differences between the groups.\n",
    "\n",
    "Here is an example of a situation where a post-hoc test might be necessary:\n",
    "\n",
    "A researcher is interested in the effects of a new drug on anxiety levels. The researcher conducts an ANOVA and finds that there is a significant difference in anxiety levels between the treatment group and the control group. However, the ANOVA does not tell the researcher which specific groups are different from each other. `To identify which groups are different, the researcher would need to conduct a post-hoc test.`\n",
    "\n",
    "In this example, the researcher could use the Tukey's HSD test to compare the mean anxiety levels of the treatment group to the mean anxiety levels of the control group. If the Tukey's HSD test finds a significant difference, then the researcher can conclude that the new drug is effective in reducing anxiety levels.\n",
    "\n",
    "It is important to note that post-hoc tests can increase the risk of Type I errors. A Type I error is an error that occurs when the researcher incorrectly rejects the null hypothesis. The risk of Type I errors increases as the number of post-hoc tests increases. Therefore, it is important to be conservative when interpreting the results of post-hoc tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1c8fc",
   "metadata": {},
   "source": [
    "##### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ceadc62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistics:  454.917811947933\n",
      "p-value:  8.491082594709224e-47\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate random weight loss data for each diet\n",
    "np.random.seed(42)\n",
    "diet_A = np.random.normal(loc=5.5, scale=0.5, size=30)\n",
    "diet_B = np.random.normal(loc=4.3, scale=0.3, size=30)\n",
    "diet_C = np.random.normal(loc=6.8, scale=0.2, size=30)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-Statistics: \", f_statistic)\n",
    "print(\"p-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ec349",
   "metadata": {},
   "source": [
    "We can interpret the results as follows:\n",
    "\n",
    "1. F-Statistic: The calculated F-statistic is approximately 454.91. This value is a measure of the variation between the sample means of the three diets (A, B, and C) relative to the variation within each diet. A larger F-statistic suggests that the differences between the sample means are significant.\n",
    "\n",
    "2. p-value: The p-value is an extremely small number, approximately 8.49e-47. This value represents the probability of observing the data if there were no significant differences in the mean weight loss between the three diets. A very small p-value indicates strong evidence against the null hypothesis, suggesting that there are significant differences in the mean weight loss between the diets.\n",
    "\n",
    "`Interpretation of the results:`\n",
    "- The extremely small p-value (much less than the usual significance level of 0.05) indicates strong evidence to reject the null hypothesis. Therefore, we can conclude that there are significant differences in the mean weight loss between the diets (A, B, and C).\n",
    "- The large F-statistic further supports this conclusion, indicating that the differences in mean weight loss among the diets are not due to random chance.\n",
    "\n",
    "In summary, the results suggest that at least one of the diets (A, B, or C) leads to significantly different weight loss outcomes compared to the others. Additional post hoc tests, such as Tukey's HSD or Bonferroni correction, can be performed to identify which specific pairs of diets have significantly different mean weight losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733f46e",
   "metadata": {},
   "source": [
    "##### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "882a6e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Source          SS    DF        MS         F  \\\n",
      "0            Employee Experience    0.712128   1.0  0.712128  0.194306   \n",
      "1                        Program    1.291006   2.0  0.645503  0.176127   \n",
      "2  Employee Experience * Program    1.180753   2.0  0.590377  0.161086   \n",
      "3                       Residual  307.858411  84.0  3.664981       NaN   \n",
      "\n",
      "      p-unc       np2  \n",
      "0  0.660489  0.002308  \n",
      "1  0.838820  0.004176  \n",
      "2  0.851481  0.003821  \n",
      "3       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "# Generate random data for completion time and employee experience level\n",
    "np.random.seed(42)\n",
    "completion_time = np.random.normal(loc=10, scale=2, size=90)\n",
    "employee_experience = np.random.choice(['novice', 'experienced'], size=90)\n",
    "\n",
    "# Generate data for software programs\n",
    "programs = np.tile(['Program A', 'Program B', 'Program C'], 30)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = pd.DataFrame({\n",
    "    'Completion Time': completion_time,\n",
    "    'Employee Experience': employee_experience,\n",
    "    'Program': programs\n",
    "})\n",
    "\n",
    "# Perform two-way ANOVA using pingouin\n",
    "result = pg.anova(data=data, dv='Completion Time', between=['Employee Experience', 'Program'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb67bc6",
   "metadata": {},
   "source": [
    "Based on the output from the two-way ANOVA using `pingouin`, we have the following results:\n",
    "\n",
    "1. Employee Experience (Factor 1) vs. Completion Time:\n",
    "   - The F-statistic is approximately 0.194 and the p-value is 0.660.\n",
    "   - The p-value (0.660) is greater than the significance level (usually 0.05).\n",
    "   - Therefore, there is no significant main effect of Employee Experience on Completion Time.\n",
    "   - The effect size (np2) is 0.002308, which indicates that Employee Experience explains only a very small portion of the variance in Completion Time.\n",
    "\n",
    "2. Program (Factor 2) vs. Completion Time:\n",
    "   - The F-statistic is approximately 0.176 and the p-value is 0.839.\n",
    "   - The p-value (0.839) is greater than the significance level (usually 0.05).\n",
    "   - Therefore, there is no significant main effect of Program on Completion Time.\n",
    "   - The effect size (np2) is 0.004176, which indicates that Program explains only a very small portion of the variance in Completion Time.\n",
    "\n",
    "3. Interaction Effect between Employee Experience and Program vs. Completion Time:\n",
    "   - The F-statistic is approximately 0.161 and the p-value is 0.851.\n",
    "   - The p-value (0.851) is greater than the significance level (usually 0.05).\n",
    "   - Therefore, there is no significant interaction effect between Employee Experience and Program on Completion Time.\n",
    "   - The effect size (np2) is 0.003821, which indicates that the interaction between Employee Experience and Program explains only a very small portion of the variance in Completion Time.\n",
    "\n",
    "4. Residual:\n",
    "   - The residual represents the unexplained variance in Completion Time after considering the main effects and interaction effect.\n",
    "   - The F-statistic for the residual is not applicable (NaN) as it represents the ratio of explained variance to unexplained variance.\n",
    "\n",
    "In summary, based on the results of the two-way ANOVA using `pingouin`, we do not find any significant main effects of Employee Experience or Program, nor do we find any significant interaction effect between Employee Experience and Program on Completion Time. The p-values for all factors and interactions are greater than the significance level (0.05), indicating that we fail to reject the null hypothesis. Therefore, we conclude that there are no significant differences in the average time it takes to complete the task among different Employee Experience levels and Software Programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35a954",
   "metadata": {},
   "source": [
    "##### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf9276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Sample T-Test Results:\n",
      "t-statistic: -4.754695943505281\n",
      "p-value: 3.819135262679478e-06\n",
      "The two groups have significantly different test scores.\n",
      "\n",
      "Post-Hoc Test (Tukey's HSD):\n",
      "         A             B    mean(A)    mean(B)      diff        se         T  \\\n",
      "0  Control  Experimental  68.961535  75.223046 -6.261511  1.316911 -4.754696   \n",
      "\n",
      "    p-tukey    hedges  \n",
      "0  0.000004 -0.669865  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"The two groups have significantly different test scores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n",
    "\n",
    "# Perform post hoc test (Tukey's HSD)\n",
    "if p_value < 0.05:\n",
    "    posthoc_tukey = pg.pairwise_tukey(data=pd.DataFrame({'Scores': np.concatenate([control_group, experimental_group]),\n",
    "                                                         'Group': np.concatenate([['Control']*100, ['Experimental']*100])}),\n",
    "                                      dv='Scores', between='Group')\n",
    "    print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "    print(posthoc_tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f03c1c",
   "metadata": {},
   "source": [
    "`The output suggests that there is a significant difference in test scores between the control and experimental groups. The Tukey's HSD post hoc test further confirms that the experimental group has significantly higher test scores than the control group.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e51767",
   "metadata": {},
   "source": [
    "##### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe278e",
   "metadata": {},
   "source": [
    "`In this case, we have data for three different retail stores (Store A, Store B, and Store C) on 30 different days. This is not a repeated measures design, but rather a one-way ANOVA since each measurement is independent and not taken from the same subjects.`\n",
    "\n",
    "For the sake of demonstration, we can simulate repeated measurements from the same subjects (participants) for different days and different stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fb09153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_value:  0.8295311744140914\n",
      "********************************\n",
      "Repeated Measures ANOVA Results:\n",
      "********************************\n",
      "  Source  ddof1  ddof2         F     p-unc       ng2       eps\n",
      "0  Store      2     58  0.187498  0.829531  0.001871  0.965872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "# Simulate repeated measurements from the same subjects\n",
    "np.random.seed(42)\n",
    "subjects = np.repeat(range(1, 31), 3)  # 30 subjects with 3 repeated measurements each\n",
    "\n",
    "# Simulate daily sales data for each store for each subject\n",
    "store_A_sales = np.random.normal(loc=1000, scale=100, size=30)\n",
    "store_B_sales = np.random.normal(loc=1200, scale=120, size=30)\n",
    "store_C_sales = np.random.normal(loc=900, scale=90, size=30)\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales]),\n",
    "    'Store': np.tile(['Store A', 'Store B', 'Store C'], 30),\n",
    "    'Subject': subjects\n",
    "})\n",
    "# print(data)\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "result = pg.rm_anova(data=data, dv='Sales', within='Store', subject='Subject')\n",
    "\n",
    "p_value = result['p-unc'].item()\n",
    "print('p_value: ', p_value)\n",
    "print(\"********************************\")\n",
    "print(\"Repeated Measures ANOVA Results:\")\n",
    "print(\"********************************\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Perform post hoc test (Tukey's HSD)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    posthoc_tukey = pg.pairwise_tests(data=data, dv='Sales', within='Store', subject='Subject')\n",
    "    print(\"\\nPost-Hoc Test (Tukey's HSD):\")\n",
    "    print(posthoc_tukey)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af57d7",
   "metadata": {},
   "source": [
    "The repeated measures ANOVA results suggest that there are no significant differences in the average daily sales between Store A, Store B, and Store C.\n",
    "* Since the repeated measures ANOVA did not find any significant differences between the stores, a post-hoc test  is not necessary in this scenario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
